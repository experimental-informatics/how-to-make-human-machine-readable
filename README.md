Notebooks from the Seminar:

# Human Machine Readable < WS21/22

### Introduction into programming

Georg Trogemann, Christian Heck, Mattis Kuhn, Ting Chun Liu

Basic Seminar Material/Sculpture/Code

Compact seminar 11 - 4 pm | 31.01.2022 until 11.02.2022 

Online @ BigBlueButton

[Experimental Informatics](https://en.khm.de/exMedia_experimentelle_informatik/)

Academy of Media Arts Cologne

Email: g.trogemann@khm.de, c.heck@khm.de, m.kuhn@khm.de

### Description

The generation of text by means of deep neural nets (NLG) has spread rapidly. Among other things, text-based dialog systems such as chatbots, assistance systems (Alexa/Siri) or robot journalism are increasingly used in news portals, e-commerce and social media; wherever context-based, natural language or reader-friendly texts are to be generated from structured data. Deep writing techniques have also found their way into the arts and literature with the help of models such as ELMo (Embeddings from Language Models), BERT (Bidirectional Encoder Representations from Transformers) or GPT-2/3 (Generative Pre-Training Transformer).

The goal of the seminar is that at the end each student has produced (a) text based on one of the neural language models mentioned above. No matter if poem, prose, novella, essay, manifesto, shopping list or social bot.

The course is intended as a general introduction to programming. It will not only teach skills to generate texts, but also the basics of Python, a universal programming language that can be used to program images, PDFs or web applications. Furthermore, Python is the most widely used language in programming Artificial Intelligences, especially Deep Neural Nets.

We ask for registration at [ground-zero@khm.de](mailto:ground-zero@khm.de) until 20.09.2021. No prior knowledge of programming is required to participate in the basic seminar.

# Course

## Week 1 (31.1. - 4.2.)

### Hands on Jupyter Notebooks

[Introduction](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/00_General-introductions/Introduction.ipynb)

### Hands on Python

[Python: Variables](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/00_General-introductions/python_variables.ipynb)

[Python: Loops & Lists](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/00_General-introductions/python_loops_lists.ipynb)

[Python: Booleans, If - Else, While-loop](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/00_General-introductions/python_booleans_conditionals.ipynb)

[Python: Strings, Files, Try & Except](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/00_General-introductions/python_strings_files_try.ipynb)

[Python: Functions](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/00_General-introductions/python_functions.ipynb)

[Python: Modules](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/00_General-introductions/python_modules_pypi.ipynb)

[Python: Tuples, Dictionaries, Set](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/00_General-introductions/python_tuples_dictionaries_set.ipynb)

[Python: Class / OOP](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/00_General-introductions/python_class.ipynb)

#### Hands on Datasets

[dataset-list](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/00_General-introductions/dataset-list.md) < some resources of datasets & archives

[scrape-load_textcorpora](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/00_General-introductions/scrape-load_textcorpora.ipynb) < some basic examples and code-snippets to srape, load and walk through datasets

[scraper_wikipedia](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/00_General-introductions/scraper_wikipedia.ipynb) < extract text of specific wikipedia articles

[clean_datasets](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/00_General-introductions/clean-token-read.ipynb)

[clean_multiple_files](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/00_General-introductions/clean_multiple_files.ipynb) < define a function to clean text and apply it to multiple files

[extract_with_pdfplumber](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/00_General-introductions/extract_with_pdfplumber.ipynb) < extract text from a pdf and remove unwanted parts/ characters


#### Coding books with Python

[First book](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/00_General-introductions/books_1.ipynb)

[Programmed books 2](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/00_General-introductions/books_2.ipynb)

[Programmed books 3](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/00_General-introductions/books_3.ipynb)

[Programmed books 4](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/00_General-introductions/books_4.ipynb)

---

## Week 2 (7.2. - 11.2.)

### Hands on Text as Data

[0-order text generation](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/02_Markov-Chain/0-order_text_generation.ipynb) < random word generation, wiederholung von Char, String and List 

[Data cleaning and Parsing](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/02_Markov-Chain/Data_cleaning_and_Parsing.ipynb) < python method for parsing text as data

[1-order text generation and Probability](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/02_Markov-Chain/1-order_text_generation.ipynb) < probability calculation

### Hands on Markov Chain

[Markov Chain - Background and knowledge](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/02_Markov-Chain/Markov_Chain_0_Background_and_knowledge.ipynb) < basic knowledge of Markov chain

[Markov Chain - Basic (Second Order Text Generation](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/02_Markov-Chain/Markov_Chain_1_Basic_Second_Order.ipynb) < Basic usage of Markov chain with second order text generation.

[Markov Chain - N-order Text Generation](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/02_Markov-Chain/Markov_Chain_2_N-order_Text_Generation.ipynb) < N-Order text generation.

[Markov Chain - OOP](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/02_Markov-Chain/Markov_Chain_3_Class.ipynb) < Markov Chain based on object oriented programming.

[Markov Chain - Markovify-library](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/02_Markov-Chain/Markov_Chain_Markovify_Library.ipynb) < Markov Chain based on github repo https://github.com/jsvine/markovify

[Additional - Markov Chain with Image](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/02_Markov-Chain/Markov_Chain_Image.ipynb) Image Generation based on Markov Chain

### Hands on Artificial Neural Networks (ANN)

[ANN-in-Keras.ipynb](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/03_ANN/Keras-ANN.ipynb) < Dense Neural Network with Keras

\+ working with [Copilot](https://copilot.github.com/)

### Hands on Recurrent Neural Networks (RNN) / Long Short Term Memory (LSTM) Networks

[Text generation with LSTM](https://github.com/experimental-informatics/how-to-make-human-machine-readable/blob/master/03_RNN/LSTM-Textgenerator.ipynb) < Text generation with RNN/LSTM

### Hands on GPT-?

[HuggingFace Pipeline](https://github.com/experimental-informatics/how-to-make-human-machine-readable/tree/master/04_GPT/huggingface-pipeline) < the HuggingFace way to use state-of-the-art NLP-models for inference

[aitextgen](https://github.com/experimental-informatics/how-to-make-human-machine-readable/tree/master/04_GPT/aitextgen) < Python tool for text-based AI training and generation using GPT-2

---

### General Info 

**Executing the Notebooks:**

- *You can run, execute and work on the Notebooks in typing following button:* [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/experimental-informatics/how-to-make-human-machine-readable/HEAD)

<!--
**Folder in KHM-Cloud:**

- *[??Here??](https://wolke.khm.de/LINK?) you can find some material for the seminar*
-->
---
### Cheat Sheets

| Title                       | URL                                                          |
| --------------------------- | ------------------------------------------------------------ |
| Python Beginner Cheat Sheet | https://github.com/ehmatthes/pcc/releases/download/v1.0.0/beginners_python_cheat_sheet_pcc_all.pdf |
| Markdown Syntax             | https://help.github.com/articles/basic-writing-and-formatting-syntax/ |
| Jupyter Notebook            | https://cheatography.com/weidadeyue/cheat-sheets/jupyter-notebook/pdf_bw/ |
| Conda                       | https://docs.conda.io/projects/conda/en/latest/_downloads/843d9e0198f2a193a3484886fa28163c/conda-cheatsheet.pdf |

---

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/experimental-informatics/how-to-make-human-machine-readable/HEAD)
