{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov simple\n",
    "\n",
    "This notebook uses the code of 'N-Order text generation' from the Notebook [n_order_text_generation](https://github.com/experimental-informatics/hands-on-text-generators/blob/master/n_order_text_generation.ipynb) in a simplified version - better to use, less easy to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to create a vocabulary\n",
    "\n",
    "Insert your text (as string) into the function.<br>\n",
    "There is an optional argument n.<br>\n",
    "The function returns the vocabulary as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary(txt, n=6):\n",
    "    \n",
    "    # Store all inside a temporary vocabulary.\n",
    "    temp_vocabulary = {}\n",
    "\n",
    "    for i in range(len(txt) -n): # Now it's important to stop the loop at len() - n.\n",
    "\n",
    "        # The current token (i) and the next tokens (i+n) are key.\n",
    "        key = txt[i:i+n]\n",
    "\n",
    "        # The next token after the last token of key is the corresponding value.\n",
    "        value = txt[i+n]\n",
    "\n",
    "        # First check if the key exists in the dictionary already.\n",
    "        if key in temp_vocabulary.keys():\n",
    "            # If yes, append the value to the list.\n",
    "            temp_vocabulary[key].append(value)\n",
    "\n",
    "        # Else insert the new key + the value in form of a [list].\n",
    "        else:\n",
    "            temp_vocabulary[key] = [value]\n",
    "            \n",
    "    # Return the vocabulary.\n",
    "    \n",
    "    return temp_vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to generate text\n",
    "\n",
    "We will insert our created vocabulary.<br>\n",
    "Optional arguments are\n",
    "- number_of_tokens\n",
    "- input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(vocabulary, number_of_tokens=100, input_=''):\n",
    "    \n",
    "    import random\n",
    "    \n",
    "    n = len(random.choice(list(vocabulary.keys())))\n",
    "    \n",
    "    generated_text = input_\n",
    "    \n",
    "    # pick a random key if input_ is empty or too short\n",
    "    if len(generated_text) < n or generated_text[-n:] not in list(vocabulary.keys()):\n",
    "        \n",
    "        generated_text += random.choice(list(vocabulary.keys()))\n",
    "    \n",
    "    for i in range(number_of_tokens):\n",
    "        \n",
    "        # get last n token as key\n",
    "        key = generated_text[-n:]\n",
    "        \n",
    "        # append a random choice of the options to our text\n",
    "        generated_text += random.choice(vocabulary[key])\n",
    "        \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the functions to generate text\n",
    "\n",
    "If you have executed the two functions above, all you have to do is to work with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aesthetics is a branch of philosophy that deals with the nature  of  beauty and taste, as well as th\n"
     ]
    }
   ],
   "source": [
    "''' Load your text. '''\n",
    "\n",
    "with open('data/wiki_selection.txt', 'r', encoding='utf-8') as f:\n",
    "    txt = f.read()\n",
    "print(txt[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Define the vocabulary. '''\n",
    "\n",
    "vocabulary = create_vocabulary(txt, n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A generated text is the hypotheses (and not have to be a predicate is true. If the class of tasks T and perhaps inseparable (though determinacy of meaningless, or the eff\n"
     ]
    }
   ],
   "source": [
    "''' Generate text. '''\n",
    "\n",
    "input_ = 'A generated text is '\n",
    "new_text = generate_text(vocabulary, number_of_tokens=150, input_=input_)\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Generate the past\n",
    "\n",
    "Predictive models are well known for predicting the future based on historic data. But we're also guessing about the past. Through reversing our text we can generate new text that leads to a desired end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ".rehtona eno htiw yrav-oc dna tcurtsnoc-oc ygolonhcet dna secrof laicos taht setats taht namdeirF \n"
     ]
    }
   ],
   "source": [
    "''' Load and reverse your text. '''\n",
    "\n",
    "with open('data/wiki_selection.txt', 'r', encoding='utf-8') as f:\n",
    "    txt = f.read()\n",
    "    # Reverse text.\n",
    "    txt = txt[::-1]\n",
    "print(txt[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Define the vocabulary. '''\n",
    "\n",
    "vocabulary = create_vocabulary(txt, n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ytitnedi citehtsea eht si scitsitats fo erutcurtsnocer ot seirt yllaitnetop ro elttil evah llits tub ,metsys ot deilppa neeb evah ,nartA ttocS dna tsitnegremE nA :noitazimitpO\n",
      "\n",
      "\n",
      "Optimization: An Emergentist and Scott Atran, have been applied to system, but still have little or potentially tries to reconstructure of statistics is the aesthetic identity.\n"
     ]
    }
   ],
   "source": [
    "''' Generate text. '''\n",
    "\n",
    "input_ = ' is the aesthetic identity.'\n",
    "input_ = input_[::-1]\n",
    "new_text = generate_text(vocabulary, number_of_tokens=150, input_=input_)\n",
    "print(new_text)\n",
    "print(new_text[::-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
