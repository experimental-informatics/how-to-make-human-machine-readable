{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Text Generation\n",
    "\n",
    "Often the completely automatic generated text is not perfect and it would be nice to *write with the machine* instead of being a passive consumer.\n",
    "\n",
    "In this notebook we will use an input field to write text *on our own*. The text generator (based on [this](https://github.com/experimental-informatics/hands-on-text-generators/blob/master/markov_basic.ipynb) notebook) will give us next token recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Libraries. '''\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from nltk.tokenize import word_tokenize as tok\n",
    "import string\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 43364 \n",
      "\n",
      "['Aesthetics', 'is', 'a', 'branch', 'of', 'philosophy', 'that', 'deals', 'with', 'the', 'nature', 'of', 'beauty', 'and', 'taste', 'as', 'well', 'as', 'the', 'philosophy', 'of', 'art', 'its', 'own', 'area', 'of', 'philosophy', 'that', 'comes', 'out', 'of', 'aesthetics', 'It', 'examines', 'subjective', 'and', 'values', 'or', 'sometimes', 'called', 'judgments', 'of', 'sentiment', 'and', 'covers', 'both', 'natural', 'and', 'artificial', 'sources']\n"
     ]
    }
   ],
   "source": [
    "''' Read text and tokenize it with NLTK. '''\n",
    "\n",
    "with open('data/wiki_selection.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "token = tok(text)\n",
    "\n",
    "''' As we will write the text it may be better to get word recommendations only (without punctuation). '''\n",
    "# remove punctuation\n",
    "token = [t for t in token if t.isalnum()]\n",
    "\n",
    "print('Number of tokens:',len(token), '\\n')\n",
    "print(token[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary\n",
    "\n",
    "Create pairs of tokens: one token as input and the preceding token as a possible output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Create a vocabulary of all tokens and map them to their preceding tokens. '''\n",
    "\n",
    "vocabulary = {}\n",
    "\n",
    "# Loop through all tokens (except the last one).\n",
    "for i in range(len(token) -1):\n",
    "    # The current token is key\n",
    "    key = token[i]\n",
    "    # The next token is the assigned value.\n",
    "    value = token[i+1]\n",
    "    \n",
    "    # Check if the key is already included into the dictionary.\n",
    "    if key in vocabulary.keys():\n",
    "        # If yes, append the value to this entry.\n",
    "        vocabulary[key].append(value)\n",
    "    else:\n",
    "        # Otherwise create a new entry with the key.\n",
    "        vocabulary[key] = [value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All options for\n",
      " Aesthetics : ['is', 'in', 'a', 'and', 'is', 'encompasses', 'examines', 'is', '2004', 'The', 'and']\n"
     ]
    }
   ],
   "source": [
    "''' Inspect all options for a given token. '''\n",
    "\n",
    "key = token[0]\n",
    "print('All options for\\n', key, ':', vocabulary[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple recommendations\n",
    "\n",
    "In the basic markov example we used the `np.random.choice()` to get one value of all the tokens stored in the dictionary for a specific token.<br>\n",
    "In this example we don't need just one token, but a recommendation of several choices.\n",
    "\n",
    "In the next step we will reduce our vocabulary, so that every token appears only once in the options.<br>\n",
    "We will make sure that the most likely token (the one that appears most often) is the most likely one in our new vocabulary.<br>\n",
    "(Nevertheless this step leads to a reduction of information.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['banana', 'apple', 'orange']\n"
     ]
    }
   ],
   "source": [
    "''' Redue and sort a list with counter(). \n",
    "See: https://stackoverflow.com/questions/53923847/sorting-a-list-by-number-of-appearances-and-removing-duplicates '''\n",
    "\n",
    "data = [\"apple\", \"apple\", \"banana\", \"orange\", \"orange\", \"banana\", \"banana\", \"apple\", \"banana\"]\n",
    "\n",
    "counts = Counter(data)\n",
    "result = sorted(counts, key=counts.get, reverse=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to apply the code above to a small dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a ['two', 'one', 'two']\n",
      "b ['one', 'two', 'two', 'zwei', 'zwei']\n",
      "c ['one', '1', 'eins']\n"
     ]
    }
   ],
   "source": [
    "''' Create a small dictionary for testing. '''\n",
    "\n",
    "ex = {}\n",
    "ex['a'] = ['two', 'one', 'two']\n",
    "ex['b'] = ['one', 'two', 'two', 'zwei', 'zwei']\n",
    "ex['c'] = ['one', '1', 'eins']\n",
    "\n",
    "for key in ex:\n",
    "    print(key, ex[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Reduce and sort it with the method from above. '''\n",
    "\n",
    "for key in ex:\n",
    "    # store all options in a list\n",
    "    options = ex[key]\n",
    "    # create a counter object with this list\n",
    "    counts = Counter(options)\n",
    "    # reduce and sort the list\n",
    "    options = sorted(counts, key=counts.get, reverse=True)\n",
    "    # override the options of our key\n",
    "    ex[key] = options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a ['two', 'one']\n",
      "b ['two', 'zwei', 'one']\n",
      "c ['one', '1', 'eins']\n"
     ]
    }
   ],
   "source": [
    "''' Reduced and sorted vocabulary. '''\n",
    "\n",
    "for key in ex:\n",
    "    print(key, ex[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying our vocabulary\n",
    "\n",
    "As we now know that it works we can apply it to our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in vocabulary:\n",
    "    # store all options in a list\n",
    "    options = vocabulary[key]\n",
    "    # create a counter object with this list\n",
    "    counts = Counter(options)\n",
    "    # reduce and sort the list\n",
    "    options = sorted(counts, key=counts.get, reverse=True)\n",
    "    # override the options of our key\n",
    "    vocabulary[key] = options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All options for\n",
      " Aesthetics : ['is', 'and', 'in', 'a', 'encompasses', 'examines', '2004', 'The']\n"
     ]
    }
   ],
   "source": [
    "''' Inspect all options for a given token. '''\n",
    "\n",
    "key = token[0]\n",
    "print('All options for\\n', key, ':', vocabulary[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive notebooks\n",
    "\n",
    "With the help of the library [ipywidgets](https://ipywidgets.readthedocs.io) we can interact with our program easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "First we will have a look at it with a simple example from its [docs](https://ipywidgets.readthedocs.io/en/stable/examples/Using%20Interact.html#Basic-interact).\n",
    "\n",
    "We have to define a function first. When we later give input (like a word) to the ipywidget, it performs this function with the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b45c08ddba24e588871d4c1fe084c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='', description='input_'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f(input_)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(input_):\n",
    "    # perform some action on the input\n",
    "    return input_*2\n",
    "\n",
    "interact(f, input_='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find recommendations through our vocabulary only with whole words. So it does not make sense to look for them while we are writing a word. \n",
    "\n",
    "**We will update our function only when we type a space.** \n",
    "\n",
    "Maybe the library provides a solution for that but we can do it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc3ce1440474491bb09e4754c2a6a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='', description='input_'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f(input_)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(input_):\n",
    "    # if the last token is a space\n",
    "    if len(input_) > 0 and input_[-1] == ' ':\n",
    "        return input_*2\n",
    "    # else do nothing\n",
    "\n",
    "interact(f, input_='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b44cd521124408977d5bd1ca4d4def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='', description='input_'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.recommendations(input_)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommendations(input_):\n",
    "    if len(input_) > 0 and input_[-1] == ' ':\n",
    "        # get the last token of our input if possible\n",
    "        if len(tok(input_)) > 0:\n",
    "            last_token = tok(input_)[-1]\n",
    "        else:\n",
    "            last_token = None\n",
    "        # check if token is included into the dictionary\n",
    "        if not last_token in vocabulary.keys():\n",
    "            # pick a random choice if not included\n",
    "            last_token = random.choice(list(vocabulary.keys()))\n",
    "        # get all options for the token\n",
    "        options = vocabulary[last_token]\n",
    "        # return this options\n",
    "        return options\n",
    "\n",
    "interact(recommendations, input_='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced interactive text generation\n",
    "\n",
    "Below we will use a larger input field (textarea) to write/ generate our text.<br>\n",
    "Furthermore we can easily access our generated text afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482c79a394404a0eafb4d3dae24ec389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Input:', layout=Layout(height='200px', width='65%'), placeholder='Type somethiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad06e3c555424e239e97ef556260bbf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Create a widget object. \n",
    "https://ipywidgets.readthedocs.io/en/stable/examples/Widget%20Basics.html '''\n",
    "\n",
    "w = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Type something. Press space to get recommendations.',\n",
    "    description='Input:',\n",
    "    layout=Layout(width='65%', height='200px'),\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "''' Widgets require an observer which listens to event changes.\n",
    "https://ipywidgets.readthedocs.io/en/stable/examples/Widget%20Events.html '''\n",
    "\n",
    "def on_change(change):\n",
    "    # clear output\n",
    "    display_recommendations.clear_output()\n",
    "    # define destination of output below\n",
    "    with display_recommendations:\n",
    "        # call our function\n",
    "        print(recommendations(change['new']))  \n",
    "    \n",
    "\n",
    "''' This listener calls the function on_change() if the value changes. '''\n",
    "w.observe(on_change, names='value')\n",
    "\n",
    "display_recommendations = widgets.Output()\n",
    "\n",
    "display(w, display_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The idea of language must include artificial intelligence.\n"
     ]
    }
   ],
   "source": [
    "''' We can receive our text with calling value. '''\n",
    "\n",
    "print(w.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "- try it without stopwords\n",
    "- limit the recommendations to a small number\n",
    "- combine this notebook with the n-grams notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
